llm_config:
  user_temperature: 0.8
  dealer_temperature: 0.3


obfuscator:
  model: ernie-5.0-thinking-preview
  api_key: bce-v3/ALTAK-RYQPp5JvoaPQ8lF8I6sWN/4137885523aab5db8ee59642fe95572523fcd926
  base_url: https://qianfan.baidubce.com/v2/
  obfuscate: ./prompts/obfuscation_prompt.txt
  strategy: ./prompts/strategy_prompt.txt
  system: ./prompts/obfuscation_system_prompt.txt

reviewer:
  model: ernie-5.0-thinking-preview
  api_key: bce-v3/ALTAK-RYQPp5JvoaPQ8lF8I6sWN/4137885523aab5db8ee59642fe95572523fcd926
  base_url: https://qianfan.baidubce.com/v2/
  review: ./prompts/verify_prompt.txt

reflection:
  model: ernie-5.0-thinking-preview
  api_key: bce-v3/ALTAK-RYQPp5JvoaPQ8lF8I6sWN/4137885523aab5db8ee59642fe95572523fcd926
  base_url: https://qianfan.baidubce.com/v2/
  reflection: ./prompts/reflection_prompt.txt
  strategy: strategy_prompt.txt

reward:
  model: deepseek-r1-250120
  api_key: 208defcd-b154-4603-9f9c-a66b5431f06a
  base_url: https://ark.cn-beijing.volces.com/api/v3
  reward: reward_prompt.txt

# This file contains all configurable parameters for the HGM system.

# Language Model Configuration
llm:
  # Model used for self-improvement tasks
  self_improve_llm: "gpt-5-mini"

  # Model used for downstream evaluation tasks
  downstream_llm: "gpt-5-mini"

  # Model used for problem diagnosis
  diagnose_llm: "gpt-5-mini"

# Optimization Algorithm Parameters
optimization:
  # Alpha parameter for node expansion (controls exploration vs exploitation)
  alpha: 0.6

  # Beta parameter for cooling down factor
  beta: 1.0

  # Whether to use decreasing temperature over iterations
  cool_down: false

  # Randomness level for evaluation task selection (0.0 = deterministic, 1.0 = fully random)
  eval_random_level: 1.0

  # Number of pseudo descendant evaluations for tree search
  n_pseudo_descendant_evals: 10000

# Execution and Resource Management
execution:
  # Number of parallel workers for self-improvement attempts
  max_workers: 20

  # Timeout for self-improvement attempts (in seconds)
  self_improve_timeout: 3600  # 1 hour

  # Timeout for evaluation attempts (in seconds)
  evaluation_timeout: 3600   # 1 hour

  # Maximum number of task evaluations (evolution iterations)
  max_task_evals: 800

# Evaluation Settings
evaluation:
  # Skip full evaluation on SWE-bench if node is top N performing
  full_eval: false

  # Use Polyglot benchmark instead of SWE-bench
  polyglot: false

# Path Configuration
paths:
  # Output directory for results (if null, will be auto-generated)
  output_dir: null

  # Directory to continue a previous run from
  continue_from: null

  # Name of the initial agent (required)
  initial_agent_name: "default_agent"